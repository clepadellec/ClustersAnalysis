d.data <- dist(data.cr)
#CAH - crit?re de Ward
#method = ? ward.D2 ? correspond au vrai crit?re de Ward
#utilisant le carr? de la distance
cah.ward <- hclust(d.data,method="ward.D2")
#affichage dendrogramme
plot(cah.ward)
#Au vu du dendogramme, on pourrait d?cider d?cider de d?couper en 5 classes
#On regarde l'inertie expliqu?e par classes
inertie <- sort(cah.ward$height, decreasing = TRUE)
plot(inertie[1:20], type = "s", xlab = "Nombre de classes", ylab = "Inertie")
#On remarque des sauts assez cons?quents jusque la classe 6, puis les sauts deviennent plus faibles
#On peut donc choisir de d?couper en 6 groupes
#dendrogramme avec mat?rialisation des groupes
plot(cah.ward)
rect.hclust(cah.ward,k=6)
#d?coupage en 6 groupes
groupes.cah <- cutree(cah.ward,k=6)
#liste des groupes
print(sort(groupes.cah))
#difficile d'analyser les groupes au 1er abord, on va donc compl?ter l'analyse avec une acp norm?e
#ACP norm?e
acp <- princomp(data,cor=T,scores=T)
#screeplot - 1 axe retenu
plot(1:10,acp$sdev^2,type="b",xlab="Nb. de facteurs",ylab="Val. Propres")
#biplot
biplot(acp,cex=0.60,col=c("orange","red"),xlim=c(-0.3,0.3),ylim=c(-0.45,0.25))
#On distingue clairement un individu atypique : le luxembourg qui a une empreinte tr?s ?lev?e par rapport aux autres pays
#positionnement des groupes dans le plan factoriel avec ?tiquettes des points
plot(acp$scores[,1],acp$scores[,2],type="n",xlim=c(-5,5),ylim=c(-5,5))
text(acp$scores[,1],acp$scores[,2],col=c("red","green","blue","black","orange","grey")[groupes.cah],cex
=0.65,labels=rownames(data),xlim=c(-5,5),ylim=c(-5,5))
#A premi?re vu on remarque qu'on a, du c?t? positif de l'axe, les pays qui ont des fortes valeurs dans les variables esp?rance, in?galit?s d'esp?rance, bien ?tre, heureux, in?galit? de bien ?tre et une faible valeur concernant les in?galit?s de revenus. A l'inverse, du c?t? n?gatif, on retrouve les pays qui ont de fortes in?galit?s de revenus mais de faibles valeurs dans les variables esp?rance, in?galit?s d'esp?rance, bien ?tre, heureux, in?galit? de bien ?tre.
#2 individus sont isol?s car ils poss?dent une population tr?s ?lev?e : L'inde et la Chine
#Nous savions ?galement que le PIB aurait un impact sur la construction des groupes, nous d?cidons donc
#de refaire une classification sans le luxembourg et sans les variables pib/population
#CAH sans le luxembourg, pib, population
data <- data_0[-73,1:8]
#Certaines variables n'ont pas les m?mes ?chelles de grandeurs
#On d?cide donc de centrer et r?duire les donn?es
data.cr<-scale(data, center = T, scale=T)
#matrice des distances entre individus
d.data <- dist(data.cr)
#CAH - crit?re de Ward
#method = ? ward.D2 ? correspond au vrai crit?re de Ward
#utilisant le carr? de la distance
cah.ward <- hclust(d.data,method="ward.D2")
#affichage dendrogramme
plot(cah.ward)
#Au vu du dendogramme, on pourrait d?cider d?cider de d?couper en 4 classes
#On regarde l'inertie expliqu?e par classes
inertie <- sort(cah.ward$height, decreasing = TRUE)
plot(inertie[1:20], type = "s", xlab = "Nombre de classes", ylab = "Inertie")
#On remarque des sauts assez cons?quents jusque la classe 5, puis les sauts deviennent plus faibles
#On peut donc choisir de d?couper en 5 groupes
#dendrogramme avec mat?rialisation des groupes
plot(cah.ward)
rect.hclust(cah.ward,k=5)
#d?coupage en 5 groupes
groupes.cah <- cutree(cah.ward,k=5)
#liste des groupes
print(sort(groupes.cah))
#difficile d'analyser les groupes au 1er abord, on va donc compl?ter l'analyse avec une acp norm?e
#ACP norm?e
acp <- princomp(data,cor=T,scores=T)
var <- get_pca_var(acp) #Creation d'une variable "var" avec tous les resultats concernants les variables
var
coord = var$coord[,1]
contrib = var$contrib[,1]
cos2 = var$cos2[,1]
display = cbind(coord, contrib, cos2)
display
#screeplot - 1 axe retenu
plot(1:8,acp$sdev^2,type="b",xlab="Nb. de facteurs",ylab="Val. Propres")
#biplot
biplot(acp,cex=0.6,col=c("orange","red"))
#positionnement des groupes dans le plan factoriel avec ?tiquettes des points
plot(acp$scores[,1],acp$scores[,2],type="n",xlim=c(-5,5),ylim=c(-5,5))
text(acp$scores[,1],acp$scores[,2],col=c("red","green","blue","black","orange")[groupes.cah],cex
=0.65,labels=rownames(data),xlim=c(-5,5),ylim=c(-5,5))
#Le graphique suffit ? r?sumer l'information il oppose les pays ayant un fort taux d'in?galit?s de revenu et de faible in?galit?s BE/Esperance et de  faible valeurs  dans : heureux esperance et bien ?tre aux pays qui ont des fortes valeurs dans les variables esp?rance, in?galit?s d'esp?rance, bien ?tre, heureux, in?galit? de bien ?tre et une faible valeur concernant les in?galit?s de revenus
#transformation de la variable quanti "Heureux" en une variable qualitative
data_0$heureux_quali <- cut(data_0$Heureux, breaks = 4, include.lowest = TRUE, labels = c("heureux.1", "heureux.2", "heureux.3", "heureux.4"))
#affichage des fr?quence
freq(data_0$heureux_quali)
#on supprime les variables quantitaives
data = data_0[-c(1:11)]
#on s'assure que tout est bien en cha?ne de caract?re
str(data)
names(data) #noms des variables restantes
data$liberte_internet<- factor(data$liberte_internet, levels = c("F", "PF","NF"))
#Mise en place de l'AFC
res.ca <- CA(contingence_h_r, graph = TRUE)
#quali ordinale avec du quali ordinal
#affichage du tableau
contingence_h_r = table(data$heureux_quali, data$Region)
contingence_h_r
#graphiques
colors <- c("chartreuse4", "chartreuse1", "orange")
barplot(contingence_h_r, col=colors, main = "heureux par libert? sur internet", ylab="nombre ")
mosaicplot(contingence_h_r, col = colors)
#r?alisation des profils ligne et colonne
lprop(contingence_h_r, digits=1)#la distribution de la r?gion parmis ceux heureux || 4 profils lignes
#ensemble = profil moyen
cprop(contingence_h_r, digits=2)
#on s'uppose la d?pendance car les profils sont distincts
#Mise en place de l'AFC
res.ca <- CA(contingence_h_r, graph = TRUE)
print(res.ca)
#visualisation des valeurs propres
eig.val <- get_eigenvalue(res.ca)
eig.val
#3 valeurs propres car min(n-1)(p-1)
fviz_eig(res.ca, addlabels = TRUE, ylim = c(0,100))#graphique des valeurs propres avec la
#Visualisation des profils lignes et colonnes dans un meme graphique
#on garde que 1 axe, car coude + 73% d'inertie
fviz_ca_biplot (res.ca, repel = TRUE) #argument repel pour eviter le chevauchement
#on va corriger les valeurs propres avec la correction de Benz?cri
res.mca.ben = epMCA(data[,1:5], graphs = FALSE, correction = "b")
fviz_eig(res.mca.ben)
#donc toute l'inertie sur l'axe 1
#Rzsultats pour les individus (= points lignes)
#
ind <- get_mca_ind (res.mca)
ind
ind$coord# Coordonnees des profils lignes
ind$cos2# Cos2: qualite de representation des profils lignes
ind$contrib# Contributions aux axes des profils lignes
#Visualisation des points lignes
fviz_mca_ind(res.mca, select.ind = list(cos2 = 80),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE
)
#du cot? + de l'axe 1 on retrouve Australie, Autriche, Belgique, Canada,etc
#du cot? - de l'axe 1 on retrouve Chine, Afghanistan, Turkemistan, Ethipi, etc
#ces deux groupes de pays ne seront pas not? de la m?me facon
#Resultats pour les modalites (=points colonnes)
#
var <- get_mca_var(res.mca)
var
head(var$coord)# Coordonnees des points colonnes
head(var$cos2)# Cos2: qualite de representation des points colonnes
head(var$contrib)# Contributions aux axes des points colonnes
fviz_mca_var (res.mca, choice = "mca.cor", repel = TRUE) #Visualisation de la correlation des variables avec les axes
corrplot(var$cos2, is.corr=FALSE)# graphique du Cos2 des points colonnes sur tous les axes
fviz_cos2(res.mca, choice = "var")# graphique du Cos2 des points colonnes sur le 1er axe
corrplot(var$contrib, is.corr=FALSE)# graphique de la contributions des points colonnes sur tous les axes
fviz_contrib(res.mca, choice = "var")# graphique de la contribution des points colonnes sur le 1er axe
#Rzsultats pour les individus (= points lignes)
#
ind <- get_mca_ind (res.mca)
ind
ind$coord# Coordonnees des profils lignes
ind$cos2# Cos2: qualite de representation des profils lignes
ind$contrib# Contributions aux axes des profils lignes
#Visualisation des points lignes
fviz_mca_ind(res.mca, select.ind = list(cos2 = 80),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE
)
#du cot? + de l'axe 1 on retrouve Australie, Autriche, Belgique, Canada,etc
#du cot? - de l'axe 1 on retrouve Chine, Afghanistan, Turkemistan, Ethipi, etc
#ces deux groupes de pays ne seront pas not? de la m?me facon
data = data_0[c(8,14:16,18)]
rownames(data)<-'.'
rownames(data)<-seq(c='.',nrow(data))
rownames(data)<-rep('.',nrow(data))
rownames(data)<-NULL
print(data)
res.mca <- MCA (data, quanti.sup = 1, graph = TRUE)  #calcul de l'ACM, resultats mis dans une variable
# Analyse correspondances multiples (ACM)
res.mca <- MCA (data, quanti.sup = 1, graph = TRUE)  #calcul de l'ACM, resultats mis dans une variable
print(res.mca) #Variable resultat contient tous les elements suivants
#p-s valeurs propres avec s = nb de variables
#ici 15 (13-4)
#Visualisation des valeurs propres
eig.val <- get_eigenvalue(res.mca)
eig.val
fviz_eig(res.mca, addlabels = TRUE, ylim = c(0, 50)) #graphique des valeurs propres avec la fonction fviz_eig() ou fviz_screeplot() du package factoextra
#avec coude on garde 1 axe, (1/9 = 0.111 donc 11%), donc il devrait avoir 11 sur chaque axe, dans le 1 on en retrouve 28
#donc c'est beaucoup plus, donc il est bien repr?sentatif
#pour l'axe 2, par rapport ? moyenne, il est au dessus
#on va corriger les valeurs propres avec la correction de Benz?cri
res.mca.ben = epMCA(data[,1:5], graphs = FALSE, correction = "b")
fviz_eig(res.mca.ben)
#donc toute l'inertie sur l'axe 1
#Rzsultats pour les individus (= points lignes)
#
ind <- get_mca_ind (res.mca)
ind
ind$coord# Coordonnees des profils lignes
ind$cos2# Cos2: qualite de representation des profils lignes
ind$contrib# Contributions aux axes des profils lignes
#Visualisation des points lignes
fviz_mca_ind(res.mca, select.ind = list(cos2 = 80),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE
)
#du cot? + de l'axe 1 on retrouve Australie, Autriche, Belgique, Canada,etc
#du cot? - de l'axe 1 on retrouve Chine, Afghanistan, Turkemistan, Ethipi, etc
#ces deux groupes de pays ne seront pas not? de la m?me facon
#Rzsultats pour les individus (= points lignes)
#
ind <- get_mca_ind (res.mca)
ind
ind$coord# Coordonnees des profils lignes
ind$cos2# Cos2: qualite de representation des profils lignes
ind$contrib# Contributions aux axes des profils lignes
#Visualisation des points lignes
fviz_mca_ind(res.mca, select.ind = list(cos2 = 80),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),geom="point"
repel = TRUE
#Rzsultats pour les individus (= points lignes)
#
ind <- get_mca_ind (res.mca)
ind
ind$coord# Coordonnees des profils lignes
ind$cos2# Cos2: qualite de representation des profils lignes
ind$contrib# Contributions aux axes des profils lignes
#Visualisation des points lignes
fviz_mca_ind(res.mca, select.ind = list(cos2 = 80),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),geom="point",
repel = TRUE
)
#du cot? + de l'axe 1 on retrouve Australie, Autriche, Belgique, Canada,etc
#du cot? - de l'axe 1 on retrouve Chine, Afghanistan, Turkemistan, Ethipi, etc
#ces deux groupes de pays ne seront pas not? de la m?me facon
#Rzsultats pour les individus (= points lignes)
#
ind <- get_mca_ind (res.mca)
ind
ind$coord# Coordonnees des profils lignes
ind$cos2# Cos2: qualite de representation des profils lignes
ind$contrib# Contributions aux axes des profils lignes
#Visualisation des points lignes
fviz_mca_ind(res.mca, select.ind = list(cos2 = 80),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),geom="text",
repel = TRUE
)
#du cot? + de l'axe 1 on retrouve Australie, Autriche, Belgique, Canada,etc
#du cot? - de l'axe 1 on retrouve Chine, Afghanistan, Turkemistan, Ethipi, etc
#ces deux groupes de pays ne seront pas not? de la m?me facon
#Rzsultats pour les individus (= points lignes)
#
ind <- get_mca_ind (res.mca)
ind
ind$coord# Coordonnees des profils lignes
ind$cos2# Cos2: qualite de representation des profils lignes
ind$contrib# Contributions aux axes des profils lignes
#Visualisation des points lignes
fviz_mca_ind(res.mca[1,2], select.ind = list(cos2 = 80),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),geom="text",
repel = TRUE
)
#Rzsultats pour les individus (= points lignes)
#
ind <- get_mca_ind (res.mca)
ind
#ind$coord# Coordonnees des profils lignes
#ind$cos2# Cos2: qualite de representation des profils lignes
#ind$contrib# Contributions aux axes des profils lignes
#Visualisation des points lignes
fviz_mca_ind(res.mca[1,2], select.ind = list(cos2 = 80),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),geom="text",
repel = TRUE
)
#ind$cos2# Cos2: qualite de representation des profils lignes
#ind$contrib# Contributions aux axes des profils lignes
#Visualisation des points lignes
fviz_mca_ind(res.mca[1:2,], select.ind = list(cos2 = 80),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),geom="text",
repel = TRUE
)
#ind$cos2# Cos2: qualite de representation des profils lignes
#ind$contrib# Contributions aux axes des profils lignes
#Visualisation des points lignes
fviz_mca_ind(res.mca, select.ind = list(cos2 = 80),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),axes=c(3,4),geom="text",
repel = TRUE
)
v1 <- factor(round(runif(500,1,4)))
v2 <- factor(round(runif(500,1,3)))
tab <- table(v1,v2)
print(tab)
cramer.v(tab)
chisq_test_all <- function(name_var_group,data){
options(warn=-1)
others_var <- colnames(data)[colnames(data)!=name_var_group]
res <- matrix(data = NA, nrow = length(others_var), ncol = 5)
for (i in 1:length(others_var)){
res[i,1]<-name_var_group
res[i,2]<-others_var[i]
res[i,3]<-chisq.test(data[name_var_group][,1],data[others_var[i]][,1])$p.value
if (round(as.numeric(res[i,3]),5)<0.05){
res[i,4]<-"significatif"
t<- table(data[name_var_group][,1],data[others_var[i]][,1])
v<- cramer.v(t)
res[i,5]<-v
}else{
res[i,4]<-"non significatif"
res[i,5]<-NA
}
}
res <- as.data.frame(res)
colnames(res)<-c("var.groupement","var.explicative","p.value.chisq.test","interpretation","intensité(v cramer)")
return(res)
}
Data=read.csv2("Données-R-1.csv", sep=";", row.names = 1)
Data.qual<- extract_ql(data)
library(ClustersAnalysis)
Data=read.csv2("Données-R-1.csv", sep=";", row.names = 1)
Data.qual<- extract_ql(data)
chisq_test_all("Continent",Data.qual)
View(Data.qual)
View(Data)
View(Data.qual)
Data=read.csv2("Données-R-1.csv", sep=";", row.names = 1)
Data.qual<- extract_ql(data)
View(Data)
chisq_test_all("liberte_internet",Data.qual)
chisq_test_all("liberte_internet",Data.qual)
chisq_test_all("Régim_simp",Data.qual)
chisq_test_all("Régime_simp",Data.qual)
library(ClustersAnalysis)
install.packages("rlang")
install.packages("devtools")
install.packages("rlang")
library(rlang)
install.packages("rlang")
library(rlang)
library(ClustersAnalysis)
apply(data, MARGIN = 2, FUN = mean)
data
data("iris")
data=iris[,1:4]
g=iris[,5]
apply(data, MARGIN = 2, FUN = mean)
tapply(data[,1], g, FUN = mean)
tapply(data[,2], g, FUN = mean)
tapply(data[,3], g, FUN = mean)
tapply(data[,4], g, FUN = mean)
datafram(list(tapply(data[,1], g, FUN = mean),tapply(data[,2], g, FUN = mean)))
a=tapply(data[,1], g, FUN = mean)
b=tapply(data[,1], g, FUN = mean)
cbien(a,b)
cbind(a,b)
rbind(a,b)
c=c()
cbind(c,a)
rbind(c,a)
rbind(tapply(data[,1], g, FUN = mean),tapply(data[,1], g, FUN = mean))
tapply(data[,1],g,FUN = length)
install.packages("digest")
library(ClustersAnalysis)
R2_multivariate(data,g)
library(ClustersAnalysis)
R2_multivariate(data,g)
as.numeric(R2_multivariate(data,g))
rbind(c(1,2,3),c(1,2,3))
R2_multivariate(data,g)
rbind(R2_multivariate(data,g),R2_multivariate(data,g))
A=rbind(R2_multivariate(data,g),R2_multivariate(data,g))
sum(A)
library(ClustersAnalysis)
R2_multivariate(data,g)
A=matrix(c(1,2,100,200), byrow = T, ncol = 2)
A
g=c(1,2)
R2_multivariate(A,g)
library(ClustersAnalysis)
library(ClustersAnalysis)
R2_multivariate(A,g)
data=iris[,1:4]
g=iris[,5]
R2_multivariate(data,g)
R2_multivariate(data,g)
R2_multivariate(data,g)
sil_pca_plot(data,g,i=1,j=2)
sil_pca_plot(data,g,i=1,j=3)
silhouette_plot(data,g,"Euclidean")
silhouette_plot(data,g,"Euclidean")
R2_multivariate(data,g)
R2_multivariate(data,g)
data("iris")
library(ClustersAnalysis)
data=iris[,1:4]
g=iris[,5]
test.value(data,g)
data=iris[,1:4]
g=iris[,5]
test.value(data,g,4)
data=iris[,1:4]
g=iris[,5]
test.value(data,g,2)
data=iris[,1:4]
g=iris[,5]
test.value(data,g,3)
sil_pca_plot(data,g,i=1,j=2)
sil_pca_plot(data,g,i=1,j=3)
sil_pca_plot(data,g,i=1,j=2)
silhouette_ind(data,g,"Euclidean")
silhouette_plot(data,g,"Euclidean")
data=iris[,1:4]
g=iris[,5]
test.value(data,g)
library(ClustersAnalysis)
data=iris[,1:4]
g=iris[,5]
test.value(data,g)
data=iris[,1:4]
g=iris[,5]
test.value(data,g,4)
data=iris[,1:4]
g=iris[,5]
test.value(data,g,2)
data=iris[,1:4]
g=iris[,5]
test.value(data,g,3)
sil_pca_plot(data,g,i=1,j=2)
sil_pca_plot(data,g,i=1,j=3)
silhouette_ind(data,g,"Euclidean")
silhouette_plot(data,g,"Euclidean")
fisher_test_all(data,g)
for (i in 1:4){
print(kmean_rand_index(data[,i],g))
}
kmean_rand_index(data[,2:4],g)
kmean_clustering_plot(data[,2:4],g,1,2)
kmean_clustering_plot(data[,2:4],g,1,2)
library(FactoMineR)
PCA(data)
silhouette_plot(data,g,"Euclidean")
silhouette_plot(data,g,"Euclidean")
silhouette_ind(data,g,"Euclidean")
silhouette_plot(data,g,"Euclidean")
install.packages("rdist")
df <- matrix(runif(200), ncol = 2)
dist_mat <- pdist(df)
library(pdist)
library(rdist)
dist_mat <- pdist(df)
dist_mat
pdist(data)
help("pdist")
library(ClustersAnalysis)
matrix_distance(data,"Euclidean")
sqrt(sum((data[1,]-data[2,])^2))
pdist(data,"euclidean")
matrix_distance(data,"euclidean")
pdist(data,"euclidean")
pdist(data,"Euclidean")
library(ClustersAnalysis)
silhouette_ind(data,g,"euclidean")
silhouette_plot(data,g,"Euclidean")
silhouette_plot(data,g,"euclidean")
kmean_clustering_plot(data[,2:4],g,1,2)
sil_pca_plot(data,g,i=2,j=3)
sil_pca_plot(data,g,i=1,j=2)
data=iris[,1:4]
g=iris[,5]
test.value(data,g,3)
library(ClustersAnalysis)
data("iris")
library(ClustersAnalysis)
data=iris[,1:4]
g=iris[,5]
test.value(data,g)
data=iris[,1:4]
g=iris[,5]
test.value(data,g,4)
data=iris[,1:4]
g=iris[,5]
test.value(data,g,2)
data=iris[,1:4]
g=iris[,5]
test.value(data,g,3)
sil_pca_plot(data,g,i=1,j=2)
sil_pca_plot(data,g,i=1,j=3)
sil_pca_plot(data,g,i=2,j=3)
silhouette_ind(data,g,"euclidean")
silhouette_plot(data,g,"euclidean")
fisher_test_all(data,g)
for (i in 1:4){
print(kmean_rand_index(data[,i],g))
}
kmean_rand_index(data[,2:4],g)
kmean_clustering_plot(data[,2:4],g,1,2)
sil_pca_plot(data,g,i=1,j=2)
data("iris")
library(ClustersAnalysis)
data=iris[,1:4]
g=iris[,5]
test.value(data,g)
data=iris[,1:4]
g=iris[,5]
test.value(data,g,4)
data=iris[,1:4]
g=iris[,5]
test.value(data,g,2)
sil_pca_plot(data,g,i=1,j=2)
sil_pca_plot(data,g,i=1,j=3)
sil_pca_plot(data,g,i=2,j=3)
silhouette_ind(data,g,"euclidean")
silhouette_plot(data,g,"euclidean")
fisher_test_all(data,g)
for (i in 1:4){
print(kmean_rand_index(data[,i],g))
}
kmean_rand_index(data[,2:4],g)
kmean_clustering_plot(data[,2:4],g,1,2)
kmean_clustering_plot(data[,2:4],g,1,2)
R2_multivariate(data,g)
